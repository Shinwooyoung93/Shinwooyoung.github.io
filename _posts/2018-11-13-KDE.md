---
layout: post
title:  "Kernel Density Estimation"
date:   2018-11-13
use_math: true
tags:
 - R
 - korean
 - Research
---

# Kernel density estimation

## 1. Simple kernel

우리는 이론적으로 통계 data를 보았을 때 중심극한 정리에 의한 정규분포를 가정하고 문제를 풀기도 한다. 

하지만 real data는 분포를 가정하기 어려운 것이 사실이다. 따라서 갖고 있는 data들의 가정 없이 표본 데이터에 대한 확률을 바탕으로 밀도함수를 직접 추정하는 방법을 비모수 밀도 추정이라 한다. 

다시 말해, data의 성분 각각에 의미가 있다고 생각하고 분포를 주는 방식이다. 간단한 예시를 살펴보자.

```r
x <- c(4, 5, 5, 6, 12, 14, 15, 15, 16, 17)
hist(x, freq = F)
```
![](/assets/KDE/1.png)

간단한 히스토그램 그래프이다. 이 데이터의 형태를 보았을 때, 모집단의 분포를 가정하기 어려운 상황이며, 표본 데이터들의 확률을 알 수 있는 히스토그램은 비모수적 밀도 추정 방법에 기초적인 예시가 된다.

### Histogram Estimates : discrete

$$
\begin{split}
\hat{f}(a_j) = \frac{1}{n}\sum_{i = 1}^{n}I_j(X_i), \quad I_j(X_i) = 
\begin{cases}
1, & X_i = a_j \\
0, & X_i \neq a_j
\end{cases}
\end{split}
$$

### Histogram Estimates : continuous

확률변수 $X_1, \cdots, X_n$은 연속인 확률변이며 어떠한 $\xi$에 대해 $|x - \xi| < h$를 만족하면

$$
\begin{split}
P(x - \frac{h}{2} < X < x + \frac{h}{2}) = \int_{x - \frac{h}{2}}^{x + \frac{h}{2}} f(t)dt = f(\xi)h \approx f(x)h\\
\hat{f}(x) = \frac{1}{nh}\sum_{i = 1}^{n}I_h(x - X_i), \quad I_h(X_i) = 
\begin{cases}
1, & - \frac{h}{2} < x < \frac{h}{2} \\
0, & \text{otherwise}
\end{cases}
\end{split}
$$

$$
\begin{split}
E[\hat{f}(x)] \rightarrow f(x), \text{as} \; h \rightarrow 0
\end{split}
$$

그렇다면 이제 커널의 정의를 해보겠다. 위의 방법은 커널밀도추정에 쓰이는 가장 기초적인 방법이다.

* $\int_{-\infty}^{\infty}K(u)du = 1$


* $K(u) = K(-u), \enspace \forall \: u$


* $K(u) \geq 0, \enspace \forall \: u$


* $K(u) = \begin{cases}
1, & |u_i| < \frac{1}{2}\enspace \forall \: i\\
0, & \text{otherwise}
\end{cases}$

그리고 우린 앞으로 $K_h(x - X_i) = \frac{1}{h}K\left( \frac{x - X_i}{h}\right)$임을 가정하며, 추정점 $x$에 대해 $h$로 이루어진 공간 안에 속할 확률을 찾는 과정이 커널밀도추정 방법이다.

이제 위의 예시에서 간단하게 점 $x$들을 추정해보자.

주어진 확률변수 $X_i = 4, 5, 5, 6, 12, 14, 15, 15, 16, 17$ 

$$
\begin{split}
P_K(x = 3) 
&= \frac{1}{nh^d}\sum_{i = 1}^{n}K\left( \frac{x - X_i}{h}\right) \\
&= \frac{1}{10\cdot 4^1}\left[K\left( \frac{3 - 4}{4}\right) + K\left( \frac{3 - 5}{4}\right) + K\left( \frac{3 - 5}{4}\right) +  \cdots + K\left( \frac{3 - 15}{4}\right) + K\left( \frac{3 - 16}{4}\right) + K\left( \frac{3 - 17}{4}\right)  \right]\\
&= \frac{1}{10\cdot 4^1}\left[1 + 0 + 0 + \cdots + 0 + 0 + 0\right] = 0.025\\
\\
P_K(x = 10) 
&= \frac{1}{nh^d}\sum_{i = 1}^{n}K\left( \frac{x - X_i}{h}\right) \\
&= \frac{1}{10\cdot 4^1}\left[K\left( \frac{10 - 4}{4}\right) + K\left( \frac{10 - 5}{4}\right) + K\left( \frac{10 - 5}{4}\right) +  \cdots + K\left( \frac{10 - 15}{4}\right) + K\left( \frac{10 - 16}{4}\right) + K\left( \frac{10 - 17}{4}\right)  \right]\\
&= \frac{1}{10\cdot 4^1}\left[0 + 0 + 0 + \cdots + 0 + 0 + 0\right] = 0\\
\\
P_K(x = 15) 
&= \frac{1}{nh^d}\sum_{i = 1}^{n}K\left( \frac{x - X_i}{h}\right) \\
&= \frac{1}{10\cdot 4^1}\left[K\left( \frac{15 - 4}{4}\right) + K\left( \frac{15 - 5}{4}\right) + K\left( \frac{15 - 5}{4}\right) +  \cdots + K\left( \frac{15 - 15}{4}\right) + K\left( \frac{15 - 16}{4}\right) + K\left( \frac{15 - 17}{4}\right)  \right]\\
&= \frac{1}{10\cdot 4^1}\left[0 + 0 + 0 + \cdots + 1 + 1 + 0\right] = 0.1
\end{split}
$$

```r
rm(list = ls())

x <- c(4, 5, 5, 6, 12, 14, 15, 15, 16, 17)
y <- seq(-2, 20, by = 0.01)
z1 <- rep(0, length(y))
z2 <- rep(0, length(y))

# set uniform kernel function
K <- function(y, x, h){
  k <- 1/length(x)/(h^ncol(as.matrix(x)))*sum(ifelse(abs((y - x)/h) < 1/2, 1, 0))}

# iteration
for(i in 1:length(y)){z1[i] <- K(y[i], x, h = 3)}
for(i in 1:length(y)){z2[i] <- K(y[i], x, h = 1)}

par(mfrow = c(1,2))
hist(x, freq = F, xlim = c(min(y), max(y)), main = "h = 3 graph")
points(y, z1, type = "l", col = "red", lwd = 2)

hist(x, freq = F, xlim = c(min(y), max(y)), main = "h = 1 graph")
points(y, z2, type = "l", col = "red", lwd = 2)
```

![](/assets/KDE/2.png)

위의 그래프를 살펴보면 $h$가 작아질 수록 본래 갖고 있던 데이터와 별 차이가 없게 되며 density가 미분이 불가능하게 첨점이 많이 존재한다. 

따라서 미분이 가능하도록 하는 smoothing kernel을 살펴보자.

## 2. Gaussian kernel

$$
\begin{split}
P_K(x) = \frac{1}{n}\sum_{i = 1}^{n}\frac{1}{(2\pi h^2)^{\frac{d}{2}}}\exp\left(-\frac{||x - X_i||_2^2}{2h^2}\right)
\end{split}
$$

```r
x <- c(4, 5, 5, 6, 12, 14, 15, 15, 16, 17)
y <- seq(-2, 20, by = 0.01)
z1 <- rep(0, length(y))
z2 <- rep(0, length(y))

# set uniform kernel function
K <- function(y, x, h){1/length(x)/(2*pi*h^2)^(ncol(as.matrix(x))/2)*sum(exp(-(y - x)^2)/2*h^2)}

# iteration
for(i in 1:length(y)){z1[i] <- K(y[i], x, h = 3)}
for(i in 1:length(y)){z2[i] <- K(y[i], x, h = 1)}

par(mfrow = c(1,2))
hist(x, freq = F, xlim = c(min(y), max(y)), main = "h = 3 graph")
points(y, z1, type = "l", col = "red", lwd = 2)
hist(x, freq = F, xlim = c(min(y), max(y)), main = "h = 1 graph")
points(y, z2, type = "l", col = "red", lwd = 2)
```

![](/assets/KDE/3.png)

또한 gaussian kernel을 사용할 때에 최적의 $h$는 $h = \left( \frac{4\sigma^5}{3n} \right)^{\frac{1}{5}} \approx 1.06\sigma n^{-\frac{1}{5}}, \enspace \sigma \: \textrm{is sample deviance}$
