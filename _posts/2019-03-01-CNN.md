---
layout: post
title:  "Multivariate & Data mining report"
date:   2019-03-01
use_math: true
tags:
 - Python
 - english
 - Research
---

# Introduction

Convolution neural network(CNN) have been shown to be successful in the difficult task of classifying natural images, using what is known as a convolutional architecture. We see how tensorflow work, role of filters and etc at CNN. Then we use via variety tuning parameters(size of batch, drop-out layer, batch-normalization).

# Explore train, test data

```python
%reset -f
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data

(train_X, train_t), (test_X, test_t) = tf.keras.datasets.mnist.load_data()

true_image = test_X[0]
true_label = test_t[0]
fig = plt.figure(figsize = (5, 5))
true_image = np.array(true_image, dtype = 'float')
plt.imshow(true_image.reshape((28, 28)))
plt.savefig('1.png', dpi=300)
```

![](/assets/CNN/1.png)

# Tensorflow

```python
num_factors = 10
num_features = 28*28
num_units1 = 12

batch_size = 1000

# first layer
X = tf.placeholder(tf.float32, shape=[None, num_features])
w1 = tf.Variable(tf.zeros([num_features, num_units1]))
b1 = tf.Variable(tf.zeros([num_units1]))
hidden1 = tf.nn.tanh(tf.matmul(X, w1) + b1)

w2 = tf.Variable(tf.zeros([num_units1, num_factors]))
b2 = tf.Variable(tf.zeros([num_factors]))
p = tf.nn.softmax(tf.matmul(hidden1, w2) + b2)

t = tf.placeholder(tf.float32, [None, num_factors])
loss = -tf.reduce_sum(t*tf.log(p))
train_step = tf.train.AdamOptimizer().minimize(loss)

correct_prediction = tf.equal(tf.sign(p-0.5), tf.sign(t-0.5))
#correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())
```

See initial loss

```python
loss0 = sess.run(loss, feed_dict = {X: true_image.reshape([1, 784]),
                                    t: np.array(pd.get_dummies(test_t))[0:1]})                                    
loss0
```
```python
# 2.3025851
```

Activate $train$_$step$ and look loss

```python
sess.run(train_step, feed_dict = {X: true_image.reshape([1, 784]),
                                  t: np.array(pd.get_dummies(test_t))[0:1]})

loss1 = sess.run(loss, feed_dict = {X: true_image.reshape([1, 784]),
                                    t: np.array(pd.get_dummies(test_t))[0:1]})

loss1
```
```python
# 2.3007853
```

Do not ctivate $train$_$step$ and look loss

```python
loss2 = sess.run(loss, feed_dict = {X: true_image.reshape([1, 784]),
                                    t: np.array(pd.get_dummies(test_t))[0:1]})
sess.close()
del sess

loss2
```
```python
# 2.3007853
```

When we do not activate $train$_$step$, loss do not change.

# Tuning parameters

## Filter work

Filter can extract each pixels densely and is used to share weights by using many filters.

```python
def edge_filter():
    filter0 = np.array(
            [[2, 1, 0, -1, -2],
             [3, 2, 0, -2, -3],
             [4, 3, 0, -3, -4],
             [3, 2, 0, -2, -3],
             [2, 1, 0, -1, -2]]) / 23
    filter1 = np.array(
            [[2, 3, 4, 2, 3],
             [1, 2, 3, 2, 1],
             [0, 3, 0, 0, 0],
             [-1, -2, -3, -2, -1],
             [-2, -3, -4, -3, -2]]) / 23
    filter_array = np.zeros([5, 5, 1, 2])
    filter_array[:, :, 0, 0] = filter0
    filter_array[:, :, 0, 1] = filter1
    
    return tf.constant(filter_array, dtype = tf.float32)
    
X = tf.placeholder(tf.float32, [None, 784])
X_image = tf.reshape(X, [-1, 28, 28, 1])
W_conv = edge_filter()
h_conv = tf.abs(tf.nn.conv2d(X_image, W_conv, strides = [1, 1, 1, 1]
                             , padding = 'SAME'))
h_conv_cutoff = tf.nn.relu(h_conv - 0.2)    
```

$[-1, 28, 28, 1]$ means that make shape as image pixels and first $-1$ option is change data to proper image. 
$stride = [1, dx, dy, 1] = [1,1,1,1]$ means that calculate of all pixels. 
$same$ option means for a pixel in a non-existent part, the corresponding value is calculated as 0. And $valid$ option means that does not perform calculations for areas where the filter is off. 
That is, the size of the output image is reduced because the end part is cut off.

```python
sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

conv_vals = sess.run(h_conv_cutoff, 
                     feed_dict = {X: true_image.reshape([1, 784])})

fig = plt.figure(figsize = (15, 5))
ax1 = fig.add_subplot(1, 4, 1)
ax2 = fig.add_subplot(1, 4, 2)
ax3 = fig.add_subplot(1, 4, 3)
ax1.imshow(true_image.reshape((28, 28)))
ax1.set_title("True image", fontsize = 15)
ax2.imshow(conv_vals[0, :, :, 0])
ax2.set_title("filter0 image", fontsize = 15)
ax3.imshow(conv_vals[0, :, :, 1])
ax3.set_title("filter1 image", fontsize = 15)
plt.savefig('2.png', dpi=300)
```

![](/assets/CNN/2.png)

$filter0$ is extract vertical line densely and $filter1$ is extract horizonal line densely.

## Pooling

The pool layer reduces each nonoverlapping bloc $r \times r$ pixels to a single number by computing their maximum. This process reduce input variable's dimensions.

```python
h_pool = tf.nn.max_pool(h_conv_cutoff, ksize = [1, 2, 2, 1],
                       strides = [1, 2, 2, 1], padding = "SAME")
                       
pool_vals = sess.run(h_pool, 
                     feed_dict = {X: true_image.reshape([1, 784])})

fig = plt.figure(figsize = (15, 5))
ax1 = fig.add_subplot(1, 4, 1)
ax2 = fig.add_subplot(1, 4, 2)
ax3 = fig.add_subplot(1, 4, 3)
ax1.imshow(true_image.reshape((28, 28)))
ax1.set_title("True image", fontsize = 15)
ax2.imshow(pool_vals[0,:,:,0])
ax2.set_title("filter0 + pool image", fontsize = 15)
ax3.imshow(pool_vals[0,:,:,1])
ax3.set_title("filter1 + pool image", fontsize = 15)
plt.savefig('3.png', dpi=300)
```

![](/assets/CNN/3.png)

## Filter combine

This process combine filters. That is two $14 \times 14$ images to $14 \times 14 \times 2$ and input before fully connected layer.

```python
h_pool_flat = tf.reshape(h_pool, [-1, 392])

w2 = tf.Variable(tf.truncated_normal([392, 2]))
b2 = tf.Variable(tf.zeros([2]))
hidden2 = tf.nn.tanh(tf.matmul(h_pool_flat, w2) + b2)
```

## Drop-out layer

Using all observations can cause overfitting problems. So, before you move on to the next layer, put in a dropout layer.

```python
keep_prob2 = 1
drop_hidden2 = tf.nn.dropout(hidden2, keep_prob2)
```

## Batch normalization

We add normailization layer because it compresses the range of pixel values so that the pixel values do not become extremely large. That process act after pooling layer or convolve layer.

```python
norm1 = tf.contrib.layers.batch_norm(drop_hidden2, center = True, scale = True)

w0 = tf.Variable(tf.zeros([2, 10])) 
b0 = tf.Variable(tf.zeros([10]))
p = tf.nn.softmax(tf.matmul(norm1, w0) + b0)
```

And these process make $14 \times 14 \times 2$ convert to probabilty.

## Penalty term

The weight regularization is typically light, and serves several roles. The $\ell_2$ reduces problems with vollinearity, the $\ell_1$ can ignore irrelevant features, and both slow the rate of overfitting, especially with deep networks.

```python
regularizers = tf.nn.l2_loss(w0) 
lamb = 0.001
t = tf.placeholder(tf.float32, [None, 10])
loss = -tf.reduce_sum(t*tf.log(p) - lamb*regularizers)
train_step = tf.train.AdamOptimizer().minimize(loss)
sess.close()
del sess
```

# Final simulation

```python
class Batch:

    def __init__(self, data):
        self._index_in_epoch = 0
        self._epochs_completed = 0
        self._data = data
        self._num_examples = data.shape[0]
        pass

    @property
    def data(self):
        return self._data

    def next_batch(self,batch_size,shuffle = True):
        start = self._index_in_epoch
        if start == 0 and self._epochs_completed == 0:
            idx = np.arange(0, self._num_examples)
            np.random.shuffle(idx)
            self._data = self.data[idx]

        # go to the next batch
        if start + batch_size > self._num_examples:
            self._epochs_completed += 1
            rest_num_examples = self._num_examples - start
            data_rest_part = self.data[start:self._num_examples]
            idx0 = np.arange(0, self._num_examples) 
            np.random.shuffle(idx0)  
            self._data = self.data[idx0] 

            start = 0
            self._index_in_epoch = batch_size - rest_num_examples 
            end =  self._index_in_epoch  
            data_new_part =  self._data[start:end]  
            return np.concatenate((data_rest_part, data_new_part)
                                  ,axis=0),self._epochs_completed
        else:
            self._index_in_epoch += batch_size
            end = self._index_in_epoch
            return self._data[start:end], self._epochs_completed
            
train_X= train_X.reshape([60000, 28*28])#/255.0
train_t= np.array(pd.get_dummies(train_t))
test_X = test_X.reshape([10000, 28*28])#/255.0
test_t = np.array(pd.get_dummies(test_t))

num_filters1 = 10
num_factors = 10
num_features = 28*28

batch_size = 100

X = tf.placeholder(tf.float32, [None, num_features])
X_image = tf.reshape(X, [-1, 28, 28, 1])
W_conv1 = tf.Variable(tf.truncated_normal([3, 3, 1, num_filters1]
                                          , stddev = 0.1))
h_conv1 = tf.nn.conv2d(X_image, W_conv1, strides = [1, 1, 1, 1]
                       , padding = "SAME")
b_conv1 = tf.Variable(tf.constant(0.1, shape = [num_filters1]))
h_conv1_cutoff = tf.nn.relu(h_conv1 + b_conv1)
h_pool1 = tf.nn.max_pool(h_conv1_cutoff, ksize = [1, 2, 2, 1], 
                         strides = [1, 2, 2, 1], padding = "SAME")

num_filters2 = 20
W_conv2 = tf.Variable(tf.truncated_normal([5,5,num_filters1,num_filters2]
                                          , stddev = 0.1))
h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides = [1, 1, 1, 1]
                       , padding = "SAME")
b_conv2 = tf.Variable(tf.constant(0.1, shape = [num_filters2]))
h_conv2_cutoff = tf.nn.relu(h_conv2 + b_conv2)
h_pool2 = tf.nn.max_pool(h_conv2_cutoff, ksize = [1, 2, 2, 1], 
                         strides = [1, 2, 2, 1], padding = "SAME")

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*num_filters2])
norm = tf.contrib.layers.batch_norm(h_pool2_flat, scale = True)

num_unit1 = 7*7*num_filters2
#num_unit2 = 1000

#w = tf.Variable(tf.zeros([num_unit1, num_unit2]))
#b = tf.Variable(tf.zeros([num_unit2]))
#hidden2 = tf.nn.relu(tf.matmul(norm, w) + b)

#keep_prob = 0.5
#hidden2_drop = tf.nn.dropout(hidden2, keep_prob)

w0 = tf.Variable(tf.zeros([num_unit1, num_factors]))
b0 = tf.Variable(tf.zeros([num_factors]))
f = tf.matmul(norm, w0) + b0
p = tf.nn.softmax(f)

regularizers = tf.nn.l2_loss(w0)
lamb = 0.01
t = tf.placeholder(tf.float32, [None, 10])
loss = -tf.reduce_sum(t*tf.log(p) - lamb*regularizers)
train_step = tf.train.AdamOptimizer().minimize(loss)

correct_prediction = tf.equal(tf.sign(p-0.5), tf.sign(t-0.5))
#correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
```

Notice that $h\_conv\_flat$ option. 
In above, we select $h\_conv\_flat = tf.nn.relu(h\_conv - 0.1)$ but select $h\_conv\_flat = tf.nn.relu(h\_conv + b\_conv)$ in this simulation. Because in complicated simulation, it is dangerous to simply enter $0.1$, so we take this as a variable and make a choice on the neural network. 
Also if we manage complecated images, add hidden layer before fully connected.

```python
np.random.seed(1)
tf.set_random_seed(1)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

train_accuracy= []
test_accuracy = []

i = 0
combinded_train = Batch(np.c_[train_X, train_t])
p = train_X.shape[1]

for _ in range(2001):
    i += 1
    combinded_batch, epoch = combinded_train.next_batch(batch_size)
    X_batch = combinded_batch[:,0:p]
    t_batch = combinded_batch[:,p:]
    _, loss_val = sess.run([train_step, loss], 
                           feed_dict = {X: X_batch, t: t_batch})
    if i % 200 == 0 or i == 1:
        train_acc = sess.run(accuracy,feed_dict = {X:X_batch,t:t_batch})
        train_accuracy.append(train_acc)
        test_acc = sess.run(accuracy, feed_dict = {X:test_X,t:test_t})
        test_accuracy.append(test_acc)
        print('step:%d,loss:%f,Train:%f,Test:%f' 
              %(i,loss_val,train_acc,test_acc))

# step:1,loss:230.258545,Train:0.900000,Test:0.900000
# step:200,loss:19.543129,Train:0.997000,Test:0.994540
# step:400,loss:21.186403,Train:0.995000,Test:0.995900
# step:600,loss:21.310833,Train:0.993000,Test:0.996350
# step:800,loss:17.274956,Train:0.996000,Test:0.996570
# step:1000,loss:14.474040,Train:0.997000,Test:0.996500
# step:1200,loss:12.689454,Train:0.999000,Test:0.996690
# step:1400,loss:14.124783,Train:0.997000,Test:0.997000
# step:1600,loss:12.149535,Train:0.998000,Test:0.997040
# step:1800,loss:11.227583,Train:1.000000,Test:0.996660
# step:2000,loss:12.563139,Train:0.995000,Test:0.997260

fig = plt.figure(figsize = (10, 6))
subplot = fig.add_subplot(1, 1, 1)
subplot.plot(train_accuracy,linewidth = 2, label = "train accuracy")
subplot.plot(test_accuracy, linewidth = 2, label = "test accuracy")
subplot.legend(loc = 'lower right', fontsize = 'x-large')
subplot.set_title("CNN", fontsize = 20)
plt.savefig('4.png', dpi=300)
```

![](/assets/CNN/4.png)







